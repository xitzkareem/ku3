{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57db658d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time \n",
    "\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecdcf7a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully visited: BBC News - Breaking news, video and the latest top stories from the U.S. and around the world\n"
     ]
    }
   ],
   "source": [
    "browser = webdriver.Firefox() \n",
    "url = 'https://www.bbc.com/news'\n",
    "browser.get(url)\n",
    "print(f\"Successfully visited: {browser.title}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de412eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75041b2",
   "metadata": {},
   "source": [
    "Removing Cookies \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "721d2bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.switch_to.frame(browser.find_element(By.CSS_SELECTOR, \"iframe[id^='sp_message_iframe']\"))\n",
    "\n",
    "button1 = browser.find_element(By.CSS_SELECTOR, \"button[title='I agree']\")\n",
    "button1.click()\n",
    "browser.switch_to.default_content()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d931fec",
   "metadata": {},
   "source": [
    "Changes Region-Section \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "39eb6a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "button2 = browser.find_element(By.LINK_TEXT , 'Europe')\n",
    "button2.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1288b2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def scrape_via_next_button(driver, num_pages):\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    data = []\n",
    "    regions = ['US & Canada', 'UK', 'Africa', 'Asia', 'Australia', 'Europe', 'Latin America', 'Middle East']\n",
    "    for region in regions :\n",
    "        print (f'Currently proccessing {region}')\n",
    "        try :\n",
    "            region_btn = wait.until(EC.element_to_be_clickable((By.LINK_TEXT, region)))\n",
    "            region_btn.click()\n",
    "            time.sleep(3)\n",
    "        except Exception as e:\n",
    "            print(f\"Could not click region '{region}'. Skipping... Error: {e}\")\n",
    "            continue\n",
    "\n",
    "        for i in range(1, num_pages + 1):\n",
    "            print(f\"--- Processing Page {i} ---\")\n",
    "            # 1. SCRAPE THE CURRENT PAGE\n",
    "            # (Your scraping logic goes here)\n",
    "            links = browser.find_elements(By.TAG_NAME, 'a')\n",
    "            for link in links:\n",
    "                try:\n",
    "                    # 1. Try to find a headline INSIDE this link\n",
    "                    # (This will fail for menu buttons(headers,footers...), but work for article cards (trageted news \"cards\")\n",
    "                    hd = link.find_element(By.CSS_SELECTOR, \"[data-testid='card-headline']\").text\n",
    "                    summ= link.find_element(By.CSS_SELECTOR,\"[data-testid='card-description']\").text\n",
    "                    url = link.get_attribute('href')\n",
    "                    data.append  ({\n",
    "                        'Headlines' : hd ,\n",
    "                        'Summary' : summ,\n",
    "                        'URL' : url})\n",
    "    \n",
    "                    # print(f\"Headline: {hd}\")\n",
    "                    # print(f\"Summary: {summ}\")\n",
    "                    # print(f\"URL:    {url}\")\n",
    "                    # print(\"-\" * 20)\n",
    "                except:\n",
    "                    # If the link doesn't have a headline inside it, just skip it!\n",
    "                    continue    \n",
    "            # 2. CLICK NEXT (Don't click on the very last page!)\n",
    "            if i < num_pages:\n",
    "                try:\n",
    "                    # Find the 'Next' button (replace with actual ID/Class/Text)\n",
    "                    next_btn = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR,f\"button[aria-label='Go to page {i+1}']\")))\n",
    "                    # Scroll to it if necessary\n",
    "                    driver.execute_script(\"arguments[0].scrollIntoView();\", next_btn)\n",
    "                    next_btn.click()\n",
    "                    # Wait for old content to disappear (optional but recommended)\n",
    "                    time.sleep(2) \n",
    "                except Exception as e:\n",
    "                    print(f\"Could not find next button: {e}\")\n",
    "                    break\n",
    "\t    # elif i>num_pages : \n",
    "\t    # \t\t\t\ttry : \n",
    "\t    # \t\t\t\t\tbtn3 = browser.find_element(By.LINK_TEXT , 'UK')\n",
    "        \n",
    "        df = pd.DataFrame(data) \n",
    "        return df\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7cc49e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently proccessing US & Canada\n",
      "--- Processing Page 1 ---\n",
      "--- Processing Page 2 ---\n",
      "--- Processing Page 3 ---\n",
      "--- Processing Page 4 ---\n",
      "--- Processing Page 5 ---\n",
      "--- Processing Page 6 ---\n",
      "--- Processing Page 7 ---\n"
     ]
    }
   ],
   "source": [
    "df = scrape_via_next_button(browser, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b483c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Navigating to Region: US & Canada ===\n",
      "\n",
      "=== Navigating to Region: UK ===\n",
      "\n",
      "=== Navigating to Region: Africa ===\n",
      "\n",
      "=== Navigating to Region: Asia ===\n",
      "\n",
      "=== Navigating to Region: Australia ===\n",
      "\n",
      "=== Navigating to Region: Europe ===\n",
      "\n",
      "=== Navigating to Region: Latin America ===\n",
      "\n",
      "=== Navigating to Region: Middle East ===\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "    # --- OUTER LOOP: Go through each region in the list ---\n",
    "for region in regions:\n",
    "        print(f\"\\n=== Navigating to Region: {region} ===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b538b86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asg1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
